{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da091d2-c523-4549-a6ae-23f4cdd54cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext.util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import HDBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eee8c35-af10-44be-a5e1-a9af754d75c1",
   "metadata": {},
   "source": [
    "#### Load the embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da770cc-4698-4538-904b-dcd7776ac682",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = fasttext.load_model(\"cc.en.300.bin\")\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "sentence_embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690a321a-26b3-4f97-be8b-b553d7858353",
   "metadata": {},
   "source": [
    "#### Load the aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258248c8-3545-4f5f-9edc-3f432dcdf9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_aspects = pd.read_pickle('../data/product_review_aspects.pkl')\n",
    "sampled_aspects['Aspect'] = sampled_aspects['Aspect'].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf14ffa7-0e4e-4422-8376-f62f4bf3c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_aspects.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e8a1d9-90de-4cb4-9f9c-edacac3f2e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_count = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c4da3-128b-410a-b4ba-23ace8213aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_words = set(['of', 'it', 'to'])\n",
    "\n",
    "def get_mean_embedding(phrase):\n",
    "    phrase = phrase.lower()\n",
    "    res = np.zeros(300)\n",
    "    num_words = 0\n",
    "    for word in filter(lambda w: not w in skip_words, phrase.split(\" \")):\n",
    "        res += embedding_model.get_word_vector(word)\n",
    "        num_words += 1\n",
    "    \n",
    "    return res/num_words if num_words >= 1 else res\n",
    "\n",
    "def get_mean_sentence_embedding(sentences):\n",
    "    list_embeddings = sentence_embedding_model.encode(\n",
    "        sentences,\n",
    "        batch_size=192,\n",
    "        device=0,\n",
    "        show_progress_bar=False,\n",
    "    )\n",
    "    \n",
    "    np_embeddings = np.array(list_embeddings)\n",
    "    mean_embedding = np_embeddings.sum(axis=0)/(np.size(np_embeddings, 0))\n",
    "    \n",
    "    return list(mean_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4b8332-0e04-4962-a5f5-3668b994578d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampled_aspects['aspect_case_converted'] = sampled_aspects['Aspect'].str.lower()\n",
    "\n",
    "aspect_embeddings = sentence_embedding_model.encode(\n",
    "    sampled_aspects['aspect_case_converted'].tolist(),\n",
    "    batch_size=192,\n",
    "    device=0,\n",
    "    show_progress_bar=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc46335f-6ec8-4bf8-89a9-57a71cf906f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_aspects['aspect_embeddings'] = aspect_embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a101567d-3b5a-4999-9cbb-0b9ea88ac557",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_aspects['sentence_embeddings'] = sentence_embedding_model.encode(\n",
    "    sampled_aspects['RepresentativeSentence'].tolist(),\n",
    "    batch_size=192,\n",
    "    device=0,\n",
    "    show_progress_bar=False,\n",
    ").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17bfb32-cb41-4bfe-b91e-c1457c726610",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_aspects['combined_embeddings'] = sampled_aspects['aspect_embeddings'] + sampled_aspects['sentence_embeddings']\n",
    "sampled_aspects['combined_embeddings'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da285100-bd32-42f6-9f13-81199a42a779",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sampled_aspects['combined_embeddings'].head(1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49538d1d-16dc-4fb8-9340-8c1ef9ef7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy import spatial\n",
    "from sklearn import metrics\n",
    "\n",
    "def do_hdbscan_clustering(df, family_id, combine_embs=False):  \n",
    "    \n",
    "    hdbscan_model = HDBSCAN(\n",
    "        min_samples=2,\n",
    "        min_cluster_size=2, \n",
    "        metric=\"cosine\",\n",
    "        cluster_selection_epsilon=0.2, \n",
    "    )\n",
    "    output = None\n",
    "    silhouette_score = 0\n",
    "    ch_score = 0\n",
    "    db_score = 0\n",
    "    \n",
    "    if df.shape[0] > 1:\n",
    "    \n",
    "        if combine_embs:\n",
    "            labels = hdbscan_model.fit_predict(np.array(df[\"combined_embeddings\"].values.tolist()))\n",
    "        else:\n",
    "            labels = hdbscan_model.fit_predict(np.array(df[\"aspect_embeddings\"].values.tolist()))\n",
    "\n",
    "        features = np.array(df[\"Aspect\"].values.tolist())\n",
    "        output = np.vstack((features, labels)).T\n",
    "        \n",
    "        df['labels'] = hdbscan_model.labels_\n",
    "    \n",
    "        output_list = []\n",
    "        aid = 0\n",
    "        for feat, lab in zip(features, labels):\n",
    "            # print(f\"{feat}, {lab}\")\n",
    "            output_clusters[lab][feat] = 1 + output_clusters[lab].get(feat, 0)\n",
    "            output_list.append([aid, feat, lab])\n",
    "            aid += 1\n",
    "            \n",
    "        output_df = pd.DataFrame(output_list, columns=['aid', 'aspect', 'label'])\n",
    "        \n",
    "        # Group by 'category' and count the occurrences\n",
    "        grouped = output_df.groupby('label').size().reset_index(name='count')\n",
    "\n",
    "        # Sort by count in descending order\n",
    "        sorted_groups = grouped.sort_values(by='count', ascending=False)\n",
    "\n",
    "        # Select the top 10 groups\n",
    "        top_10_groups = sorted_groups.head(min(10, len(output_df.label.unique())))\n",
    "        \n",
    "        output_df_filtered = output_df[output_df['label'].isin(top_10_groups.label.unique())]\n",
    "        \n",
    "        output_df_filtered[\"aspect_embeddings\"] = sentence_embedding_model.encode(\n",
    "            output_df_filtered['aspect'].tolist(),\n",
    "            batch_size=192,\n",
    "            device=0,\n",
    "            show_progress_bar=False,\n",
    "        ).tolist()\n",
    "        \n",
    "        if len(set(output_df_filtered['label'].values)) >= 2:\n",
    "            if combine_embs:\n",
    "                silhouette_score = metrics.silhouette_score(np.array(df[\"combined_embeddings\"].values.tolist()), output_df_filtered['label'].values, metric='cosine')\n",
    "                ch_score = metrics.calinski_harabasz_score(np.array(df[\"combined_embeddings\"].values.tolist()), output_df_filtered['label'].values)\n",
    "                db_score = metrics.davies_bouldin_score(np.array(df[\"combined_embeddings\"].values.tolist()), output_df_filtered['label'].values)\n",
    "            else:\n",
    "                silhouette_score = metrics.silhouette_score(np.array(output_df_filtered[\"aspect_embeddings\"].values.tolist()), output_df_filtered['label'].values, metric='cosine')\n",
    "                ch_score = metrics.calinski_harabasz_score(np.array(output_df_filtered[\"aspect_embeddings\"].values.tolist()), output_df_filtered['label'].values)\n",
    "                db_score = metrics.davies_bouldin_score(np.array(output_df_filtered[\"aspect_embeddings\"].values.tolist()), output_df_filtered['label'].values)\n",
    "    \n",
    "    return silhouette_score, ch_score, db_score, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f38205-af51-4d62-a8b9-110311ad7adc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "output_clusters = defaultdict(dict)\n",
    "silhouette_scores = []\n",
    "ch_scores = []\n",
    "db_scores = []\n",
    "\n",
    "family_ids = sampled_aspects.ProductFamilyId.unique()\n",
    "for family_id in family_ids:\n",
    "    pf1 = sampled_aspects.loc[sampled_aspects[\"ProductFamilyId\"] == family_id]\n",
    "    for sentiment in [\"Positive\", \"Negative\"]:\n",
    "        pf1_pos = pf1.loc[pf1[\"Sentiment\"] == sentiment]\n",
    "        sil_score, ch_score, db_score, output = do_hdbscan_clustering(pf1_pos, family_id)\n",
    "        if sil_score > 0:\n",
    "            silhouette_scores.append(sil_score)\n",
    "        if ch_score > 0:\n",
    "            ch_scores.append(ch_score)\n",
    "        if db_score > 0:\n",
    "            db_scores.append(db_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64609818-f524-43c0-ba07-32e490a0ff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{round(np.mean(silhouette_scores), 2)} \\pm {round(np.std(silhouette_scores), 2)}[{round(np.min(silhouette_scores), 2)}, {round(np.max(silhouette_scores), 2)}]\")\n",
    "print(f\"{round(np.mean(ch_scores), 2)} \\pm {round(np.std(ch_scores), 2)}[{round(np.min(ch_scores), 2)}, {round(np.max(ch_scores), 2)}]\")\n",
    "print(f\"{round(np.mean(db_scores), 2)} \\pm {round(np.std(db_scores), 2)}[{round(np.min(db_scores), 2)}, {round(np.max(db_scores), 2)}]\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "mypipenv2",
   "name": "pytorch-gpu.2-0.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m109"
  },
  "kernelspec": {
   "display_name": "mypipenv2",
   "language": "python",
   "name": "mypipenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
