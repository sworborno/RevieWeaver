{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44c7499-e9b5-4506-a7a3-ec28fd268fc4",
   "metadata": {},
   "source": [
    "#### Load the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da091d2-c523-4549-a6ae-23f4cdd54cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext.util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eee8c35-af10-44be-a5e1-a9af754d75c1",
   "metadata": {},
   "source": [
    "#### Load the embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da770cc-4698-4538-904b-dcd7776ac682",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = fasttext.load_model(\"cc.en.300.bin\")\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "sentence_embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690a321a-26b3-4f97-be8b-b553d7858353",
   "metadata": {},
   "source": [
    "#### Load the aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258248c8-3545-4f5f-9edc-3f432dcdf9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_aspects = pd.read_pickle('../data/product_review_aspects.pkl')\n",
    "sampled_aspects['Aspect'] = sampled_aspects['Aspect'].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf14ffa7-0e4e-4422-8376-f62f4bf3c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_aspects.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abe6813-5828-494d-a1e3-b5c8b222b50f",
   "metadata": {},
   "source": [
    "#### Similarity parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddae688-960d-4d62-af6a-73f99a275b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 200\n",
    "SIMILARITY = 0.50\n",
    "SENTENCE_SIMILARITY = 0.40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c4da3-128b-410a-b4ba-23ace8213aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_words = set(['of', 'it', 'to'])\n",
    "\n",
    "def get_mean_embedding(phrase):\n",
    "    phrase = phrase.lower()\n",
    "    res = np.zeros(300)\n",
    "    num_words = 0\n",
    "    for word in filter(lambda w: not w in skip_words, phrase.split(\" \")):\n",
    "        res += embedding_model.get_word_vector(word)\n",
    "        num_words += 1\n",
    "    \n",
    "    return res/num_words if num_words >= 1 else res\n",
    "\n",
    "def get_mean_sentence_embedding(sentences):\n",
    "    list_embeddings = sentence_embedding_model.encode(\n",
    "        sentences,\n",
    "        batch_size=192,\n",
    "        device=0,\n",
    "        show_progress_bar=False,\n",
    "    )\n",
    "    \n",
    "    np_embeddings = np.array(list_embeddings)\n",
    "    mean_embedding = np_embeddings.sum(axis=0)/(np.size(np_embeddings, 0))\n",
    "    \n",
    "    return list(mean_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ebd00-1953-4eb4-a175-e307bc837cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(features):  # [feature, rank[p], node_reviews[p], other_names[p], feature_ids[p]]\n",
    "    # Use union find to remove duplicate features\n",
    "    # graph[p][0], rank[p], node_reviews[p], other_names[p], feature_ids[p], quotes[p], p\n",
    "    parent = [i for i in range(len(features))]\n",
    "    fids = [features[i][4] for i in range(len(features))]\n",
    "    names = [features[i][0] for i in range(len(features))]\n",
    "    rank = [features[i][1] for i in range(len(features))]\n",
    "    aspect_embedding = [features[i][7] for i in range(len(features))]\n",
    "\n",
    "    def find(u):\n",
    "        p = parent[u]\n",
    "        while p != parent[p]:\n",
    "            parent[p] = parent[parent[p]]\n",
    "            p = parent[p]\n",
    "        return p\n",
    "\n",
    "    def union(u, v):\n",
    "        p1 = find(u)\n",
    "        p2 = find(v)\n",
    "\n",
    "        if p1 == p2:\n",
    "            return\n",
    "        \n",
    "        emb1 = aspect_embedding[p1]\n",
    "        emb2 = aspect_embedding[p2]\n",
    "        \n",
    "        similarity = cosine_similarity([emb1], [emb2])[0][0]\n",
    "\n",
    "        if similarity >= 0.40:\n",
    "            if rank[p1] > rank[p2]:\n",
    "                parent[p2] = p1\n",
    "            else:\n",
    "                parent[p1] = p2\n",
    "\n",
    "    for u in range(len(features) - 1):\n",
    "        for v in range(len(features)):\n",
    "            union(u, v)\n",
    "\n",
    "    result = []\n",
    "    parent = set(parent)\n",
    "    for i, feature in enumerate(features):\n",
    "        if i in parent:\n",
    "            result.append((feature[0], feature[1], feature[2], feature[3], feature[4], feature[5]))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ee2b42-dda4-45f7-9487-471f1d244a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_features(graph):\n",
    "    def find(u):\n",
    "        p = parent[u]\n",
    "        while p != parent[p]:\n",
    "            parent[p] = parent[parent[p]]\n",
    "            p = parent[p]\n",
    "        return p\n",
    "\n",
    "    def union(u, v):\n",
    "        \n",
    "        p1 = find(u)\n",
    "        p2 = find(v)\n",
    "\n",
    "        if p1 == p2:\n",
    "            return\n",
    "\n",
    "        p1_name = graph[p1][0].lower()\n",
    "        p2_name = graph[p2][0].lower()\n",
    "        \n",
    "        emb1 = aspect_embedding[p1]\n",
    "        emb2 = aspect_embedding[p2]\n",
    "        \n",
    "        similarity = cosine_similarity([emb1], [emb2])[0][0]\n",
    "        \n",
    "        sent_emb1 = node_embedding[p1]\n",
    "        sent_emb2 = node_embedding[p2]\n",
    "        \n",
    "        sent_similarity = cosine_similarity([sent_emb1], [sent_emb2])[0][0]\n",
    "\n",
    "        if similarity >= SIMILARITY and sent_similarity >= SENTENCE_SIMILARITY:\n",
    "            if rank[p1] == rank[p2]:\n",
    "                len1 = len(p1_name)\n",
    "                len2 = len(p2_name)\n",
    "                \n",
    "                if len1 <= len2:\n",
    "                    parent[p2] = p1\n",
    "                    rank[p1] += rank[p2]\n",
    "                    node_reviews[p1].update(node_reviews[p2])\n",
    "                    other_names[p1].update(other_names[p2])\n",
    "                else:\n",
    "                    parent[p1] = p2\n",
    "                    rank[p2] += rank[p1]\n",
    "                    node_reviews[p2].update(node_reviews[p1])\n",
    "                    other_names[p2].update(other_names[p1])\n",
    "                \n",
    "            elif rank[p1] > rank[p2]:\n",
    "                parent[p2] = p1\n",
    "                rank[p1] += rank[p2]\n",
    "                node_reviews[p1].update(node_reviews[p2])\n",
    "                other_names[p1].update(other_names[p2])\n",
    "            else:\n",
    "                parent[p1] = p2\n",
    "                rank[p2] += rank[p1]\n",
    "                node_reviews[p2].update(node_reviews[p1])\n",
    "                other_names[p2].update(other_names[p1])\n",
    "\n",
    "    OPT_FEATURES = len(graph) # min(len(graph), MAX_FEATURES)\n",
    "\n",
    "    parent = [i for i in range(OPT_FEATURES)]\n",
    "    rank = [node[1] for node in graph[:OPT_FEATURES]]\n",
    "    node_name = [node[0] for node in graph[:OPT_FEATURES]]\n",
    "    node_embedding = [node[2] for node in graph[:OPT_FEATURES]]\n",
    "    \n",
    "    node_reviews = [node[3] for node in graph[:OPT_FEATURES]]\n",
    "    other_names = [set([f\"{node[0]}({node[1]})\"]) for node in graph[:OPT_FEATURES]]\n",
    "    # other_names_with_count = {node: [node[0], node[1]] for node in graph[:OPT_FEATURES]}\n",
    "    feature_ids = [node[4] for node in graph[:OPT_FEATURES]]\n",
    "    quotes = [node[5] for node in graph[:OPT_FEATURES]]\n",
    "    aspect_embedding = [node[6] for node in graph[:OPT_FEATURES]]\n",
    "\n",
    "    \n",
    "    for u in range(OPT_FEATURES - 1):\n",
    "        for v in range(u + 1, OPT_FEATURES):\n",
    "            union(u, v)\n",
    "    \n",
    "    results = []\n",
    "    for p in set(parent):\n",
    "        # print(f\"Topic: {p}, {graph[p][0]} ({rank[p]})\")\n",
    "        results.append((graph[p][0], rank[p], node_reviews[p], other_names[p], feature_ids[p], quotes[p], p, aspect_embedding[p]))\n",
    "\n",
    "    results.sort(key = lambda x:x[2], reverse=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4b8332-0e04-4962-a5f5-3668b994578d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampled_aspects['aspect_case_converted'] = sampled_aspects['Aspect'].str.lower()\n",
    "\n",
    "aspect_embeddings = sentence_embedding_model.encode(\n",
    "    sampled_aspects['aspect_case_converted'].tolist(),\n",
    "    batch_size=192,\n",
    "    device=0,\n",
    "    show_progress_bar=False,\n",
    ")\n",
    "# print(type(aspect_embeddings))\n",
    "sampled_aspects['aspect_embeddings'] = aspect_embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40918a2a-668e-4bf2-837e-78059ff45250",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_aspects['aspect_embeddings'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7acd4bf-a797-40ba-9acc-b133d09fea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "family_ids = sampled_aspects[\"ProductFamilyId\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85d3979-9f44-4b43-8d61-572edf74e55c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_results = {}\n",
    "\n",
    "for family_id in family_ids:\n",
    "    pf1 = sampled_aspects.loc[sampled_aspects[\"ProductFamilyId\"] == family_id]\n",
    "    pos_results = []\n",
    "    neg_results = []\n",
    "    results = []\n",
    "    \n",
    "    pos_features = []\n",
    "    neg_features = []\n",
    "    \n",
    "    for sentiment in [\"Positive\", \"Negative\"]:\n",
    "        pf1_pos = pf1.loc[pf1[\"Sentiment\"] == sentiment]\n",
    "\n",
    "        feature_dict = defaultdict(int)\n",
    "        sentenceid_dict = defaultdict(list)\n",
    "        reviewids_dict = defaultdict(set)\n",
    "        representative_quote_dict = defaultdict(list)\n",
    "        aspect_emb_dict = defaultdict(list)\n",
    "        feature_unique_ids = defaultdict(str)\n",
    "        uid = 0\n",
    "\n",
    "        for i, row in pf1_pos.iterrows():\n",
    "            feature = row[\"Aspect\"]\n",
    "            sentence_id = row[\"AspectId\"]\n",
    "            representative_quote = row[\"RepresentativeSentence\"]\n",
    "\n",
    "            if feature not in feature_unique_ids:\n",
    "                unique_id = str(family_id) + \"_\" + str(sentiment) + \"_\" + str(uid)\n",
    "                feature_unique_ids[feature] = unique_id\n",
    "                uid += 1\n",
    "\n",
    "            if sentence_id not in sentenceid_dict[feature]:\n",
    "                sentenceid_dict[feature].append(sentence_id)\n",
    "            reviewids_dict[feature].add(sentence_id.split(\"_\")[0])\n",
    "            feature_dict[feature] += 1\n",
    "            representative_quote_dict[feature].append(representative_quote.lower() if representative_quote is not None else \"\")\n",
    "            aspect_emb_dict[feature] = row['aspect_embeddings']\n",
    "\n",
    "        graph = []\n",
    "        threshold = MAX_FEATURES\n",
    "        for k in sorted(feature_dict, key=feature_dict.get, reverse=True):\n",
    "            reviewids = reviewids_dict[k]\n",
    "\n",
    "            feature_embedding = get_mean_sentence_embedding(representative_quote_dict[k])\n",
    "            graph.append([k, feature_dict[k], feature_embedding, reviewids, feature_unique_ids[k], representative_quote_dict[k], aspect_emb_dict[k]])\n",
    "\n",
    "            if threshold < 0:\n",
    "                break\n",
    "            threshold -= 1\n",
    "        \n",
    "        if sentiment == \"Positive\":\n",
    "            pos_features = find_top_features(graph)\n",
    "        else:\n",
    "            neg_features = find_top_features(graph)\n",
    "\n",
    "    pos_neg_features = pos_features + neg_features\n",
    "    if len(pos_neg_features) > 0 and len(neg_features) > 0:\n",
    "        final_features = remove_duplicates(pos_neg_features)\n",
    "    else:\n",
    "        final_features = pos_neg_features\n",
    "    all_results[family_id] = final_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebee76d-74b6-43c9-86a4-d9e430a83209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store the results\n",
    "# import pickle\n",
    "\n",
    "# with open('../data/results-topic-modeling-revieweaver.pkl', 'wb') as f:\n",
    "#     pickle.dump(all_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4550a6b9-7ffb-426d-90c2-dbc0171d1cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "mypipenv2",
   "name": "pytorch-gpu.2-0.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m109"
  },
  "kernelspec": {
   "display_name": "mypipenv2",
   "language": "python",
   "name": "mypipenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
