{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44c7499-e9b5-4506-a7a3-ec28fd268fc4",
   "metadata": {},
   "source": [
    "#### Load the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da091d2-c523-4549-a6ae-23f4cdd54cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext.util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import re\n",
    "import textwrap\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from uuid import uuid4\n",
    "\n",
    "from asynciolimiter import Limiter, StrictLimiter\n",
    "from google.cloud import aiplatform\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ID = \"YOUR-GCP-PROJECT-ID\"\n",
    "LOCATION = \"us-central1\" # Project location\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eee8c35-af10-44be-a5e1-a9af754d75c1",
   "metadata": {},
   "source": [
    "#### Load the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da770cc-4698-4538-904b-dcd7776ac682",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_NAME = 'gemini-1.5-flash'\n",
    "\n",
    "llm1 = VertexAI(\n",
    "    model_name=LLM_NAME,\n",
    "    max_output_tokens=2048,\n",
    "    temperature=0,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a1e09-bfe1-4ca8-a99b-b81edf732db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_per_minute = 50\n",
    "time_window = 60\n",
    "rate_limiter = StrictLimiter(requests_per_minute/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690a321a-26b3-4f97-be8b-b553d7858353",
   "metadata": {},
   "source": [
    "#### Load the distilled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258248c8-3545-4f5f-9edc-3f432dcdf9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/results-topic-modeling-revieweaver.pkl', 'rb') as f:\n",
    "    distilled_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1f7d35-dd13-4f11-91ea-4d251d3aa8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the primary review details\n",
    "review_data = pd.read_pickle('../data/product_reviews.pkl')\n",
    "review_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e4b1f-0d3e-44e6-9638-640ae4fd9920",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data_grouped = review_data.groupby(\"product_family_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eccbd5e-a56e-4e89-9662-a14bf05e7b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_distill = \"\"\"You are a helpful assistant and you are tasked with writing a summary from some given information about a product. We have a list of PROS and CONS of the product, number of times they were mentioned, and a list of representative quotes speaking about the PROS or CONS.\n",
    "\n",
    "- Write a short and concise summary with no more than four sentences and no less than three sentences on how customers are speaking about different pros and cons.\n",
    "- Use the statement '#STATEMENT#' to begin the summary.\n",
    "- Skip reporting how many times a pro/con was mentioned.\n",
    "- The summary should only highlight pros and cons that are mentioned frequently.\n",
    "- The summary should use a short name of the product.\n",
    "- Avoid or rephrase customer mentioned terms that are derogatory, disrespectful, harmful, sexually explicit, hate speech, or harassment.\n",
    "\n",
    "\n",
    "The PROS and CONS are listed below:\n",
    "\n",
    "====================================\n",
    "PROS_AND_CONS\n",
    "====================================\n",
    "\n",
    "{SUMMARY}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf66d13-8ef7-4d81-8717-f45e5b98fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_llm = \"\"\"You are a helpful assistant and you are tasked with writing a summary from a list of customer reviews.\n",
    "\n",
    "- Write a short and concise summary with no more than four sentences and no less than three sentences on how customers are speaking about different pros and cons.\n",
    "- Use the statement '#STATEMENT#' to begin the summary.\n",
    "- Skip reporting how many times a pro/con was mentioned.\n",
    "- The summary should only highlight pros and cons that are mentioned frequently.\n",
    "- The summary should use a short name of the product.\n",
    "- Avoid or rephrase customer mentioned terms that are derogatory, disrespectful, harmful, sexually explicit, hate speech, or harassment.\n",
    "\n",
    "\n",
    "The reviews are listed below:\n",
    "\n",
    "====================================\n",
    "ALL_REVIEWS\n",
    "====================================\n",
    "\n",
    "{SUMMARY}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa187cf-8193-4a2c-b452-83af40b82fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of phrases we will use to begin a summary\n",
    "SUMMARY_PREFIXES = [\n",
    "    \"Customers appreciate\",\n",
    "    \"Customers value\", \n",
    "    \"Customers highly value\", \n",
    "    \"Customers are impressed with\", \n",
    "    \"Customers praise\", \n",
    "    \"Customers are positive/negative about\",\n",
    "    \"Customers admire\",\n",
    "    \"Customers frequently mention\",\n",
    "    \"Customers commend\",\n",
    "    \"Customers are satisfied with\",\n",
    "    \"Customers often highlight\",\n",
    "    \"Customers consistently note\",\n",
    "    \"Customers find value in\",\n",
    "    \"Customers enjoy\",\n",
    "    \"Customers are enthusiastic about\",\n",
    "    \"Customers are pleased with\",\n",
    "    \"Customers recognize\",\n",
    "    \"Customers express satisfaction with\",\n",
    "    \"Customers love\",\n",
    "    \"Customers regard\",\n",
    "    \"Customers have good things to say about\",\n",
    "    \"Customers are delighted by\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558215bb-0c6f-43db-8eac-f8d04abf65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def find_priority(feature_name, repr_sentence):\n",
    "    # low value represents higher priority\n",
    "    num_words = len(repr_sentence.split(\" \"))\n",
    "    num_chars = len(repr_sentence)\n",
    "    is_feature_present = 0 if feature_name.lower() in repr_sentence.lower() else 1\n",
    "    bucket = None\n",
    "    if num_words < 5:\n",
    "        bucket = 1\n",
    "    elif num_words >= 5 and num_words < 12:\n",
    "        bucket = 0\n",
    "    elif num_words >= 12 and num_words < 20:\n",
    "        bucket = 2\n",
    "    else:\n",
    "        bucket = 3\n",
    "\n",
    "    return bucket, is_feature_present, num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f57eb-b35d-43f7-8091-75f682ea2a79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(distilled_features):\n",
    "    content_for_summarization = defaultdict()\n",
    "    content_for_summarization_llm = defaultdict()\n",
    "        \n",
    "    print(f\"Started preparing the content for review summary generation...\")\n",
    "\n",
    "    for family in review_data['product_family_id'].unique():\n",
    "\n",
    "        if family in review_data_grouped.groups.keys():\n",
    "            product_info = review_data_grouped.get_group(family).iloc[0]\n",
    "\n",
    "            metadata = dict()\n",
    "            metadata[\"brand\"] = product_info[\"brand\"]\n",
    "\n",
    "\n",
    "            ddd = dict()\n",
    "            ddd[\"PRODUCT_NAME\"] = product_info[\"short_name\"]\n",
    "            ddd[\"PROS\"] = []\n",
    "            ddd[\"CONS\"] = []\n",
    "            \n",
    "            all_features = distilled_features[f\"{family}\"] if family in distilled_features else []                                 \n",
    "            \n",
    "            if len(all_features) == 0:\n",
    "                continue\n",
    "            \n",
    "            if len(all_features[0]) == 8:\n",
    "                distilled_features_family = pd.DataFrame(all_features, columns=[\"feature_name\", \"count\", \"review_ids\", \"other_names\", \"feature_id\", \"quotes\", \"val\", \"embedding\"])\n",
    "                distilled_features_family.drop(['val', 'embedding'], axis=1, inplace=True)\n",
    "            else:\n",
    "                distilled_features_family = pd.DataFrame(all_features, columns=[\"feature_name\", \"count\", \"review_ids\", \"other_names\", \"feature_id\", \"quotes\"])\n",
    "            distilled_features_family[\"sentiment\"] = distilled_features_family[\"feature_id\"].apply(lambda x: \"Positive\" if \"Positive\" in x else \"Negative\")\n",
    "            \n",
    "            for row in distilled_features_family.values.tolist():\n",
    "                feature_name = row[0]\n",
    "                sentiment = row[6]\n",
    "                representative_quotes = list(row[5])\n",
    "                review_ids = set(row[2])\n",
    "                mentions = int(row[1]) # len(review_ids)\n",
    "                \n",
    "                top_repr_quotes = []\n",
    "                \n",
    "                for repr_quote in representative_quotes:\n",
    "                    a, b, c = find_priority(feature_name, repr_quote)\n",
    "                    heapq.heappush(top_repr_quotes, (a, b, c, repr_quote))\n",
    "                # print(top_repr_quotes[:5])\n",
    "\n",
    "                dd = dict()\n",
    "                dd[\"feature\"] = feature_name\n",
    "                dd[\"mentions\"] = mentions\n",
    "                dd[\"comments\"] = []\n",
    "\n",
    "                # print(representative_quotes)\n",
    "                for i in range(min(len(top_repr_quotes), 10)):\n",
    "                    val = heapq.heappop(top_repr_quotes)\n",
    "                    dd[\"comments\"].append(val[3])\n",
    "\n",
    "                if mentions > 0:\n",
    "                    if sentiment.upper() == \"POSITIVE\":\n",
    "                        ddd[\"PROS\"].append(dd)\n",
    "\n",
    "                    elif sentiment.upper() == \"NEGATIVE\":\n",
    "                        ddd[\"CONS\"].append(dd)\n",
    "\n",
    "            # ddd[\"PROS\"] = sorted(ddd[\"PROS\"], key=lambda d: d['mentions'], reverse=True)\n",
    "            ddd[\"PROS\"] = sorted(ddd[\"PROS\"], key=lambda d: d['mentions'], reverse=True)[:min(10, len(ddd[\"PROS\"]))]\n",
    "\n",
    "            # Do not add more than 5/10 cons\n",
    "            ddd[\"CONS\"] = sorted(ddd[\"CONS\"], key=lambda d: d['mentions'], reverse=True)[:min(10, len(ddd[\"CONS\"]))]\n",
    "            \n",
    "            randind = random.randrange(len(SUMMARY_PREFIXES))\n",
    "            new_prompt = prompt_distill.replace(\"#STATEMENT#\", SUMMARY_PREFIXES[randind])\n",
    "            \n",
    "\n",
    "            content_for_summarization[family] = {\n",
    "                \"product_family_id\": family,\n",
    "                \"metadata\": metadata, \n",
    "                \"content\": ddd,\n",
    "                \"summary\": \"\",\n",
    "                \"safety_info\": dict(),\n",
    "                \"prompt\": new_prompt\n",
    "            }\n",
    "            \n",
    "            new_prompt = prompt_llm.replace(\"#STATEMENT#\", SUMMARY_PREFIXES[randind])\n",
    "            \n",
    "            content_for_summarization_llm[family] = {\n",
    "                \"product_family_id\": family,\n",
    "                \"metadata\": metadata, \n",
    "                \"content\": review_data_grouped.get_group(family)[\"review_text\"].values,\n",
    "                \"summary\": \"\",\n",
    "                \"safety_info\": dict(),\n",
    "                \"prompt\": new_prompt\n",
    "            }\n",
    "            \n",
    "    print(f\"Finished preparing the content for review summary generation...\")\n",
    "\n",
    "    return content_for_summarization, content_for_summarization_llm\n",
    "\n",
    "# content_for_summarization, content_for_summarization_llm = prepare_data(distilled_features)\n",
    "\n",
    "# We can test it out with few products\n",
    "content_for_summarization, content_for_summarization_llm = prepare_data({k: distilled_features[k] for k in list(distilled_features)[:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcccc95-c0c2-4cbf-af6f-b0111aa52fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def executer(family_n_prompt, content_for_summarization):\n",
    "    await rate_limiter.wait()\n",
    "    max_tries = 5\n",
    "\n",
    "    family = family_n_prompt[0]\n",
    "    new_prompt = family_n_prompt[1]\n",
    "    response = None\n",
    "\n",
    "    for i in range(max_tries):\n",
    "        try:\n",
    "            r = await llm1.ainvoke(new_prompt)\n",
    "            content_for_summarization[family][\"summary\"] = r\n",
    "            return \n",
    "        except Exception as e:\n",
    "            print(f\"{e}\")\n",
    "            await asyncio.sleep(3)\n",
    "    print(f\"Skipping {family}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ee4b1a-4bdf-44aa-aba9-de60478cf59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_summary_with_rate_limit(content_for_summarization, use_all=False):\n",
    "    print(f\"Started generating review summaries for {len(content_for_summarization.keys())} families\")\n",
    "\n",
    "    per_family_prompt = []\n",
    "\n",
    "    for family in content_for_summarization.keys():\n",
    "        if use_all:\n",
    "            new_prompt = content_for_summarization[family]['prompt'].replace(\"ALL_REVIEWS\", \"\\n----\\n\".join(content_for_summarization[family][\"content\"]))\n",
    "            per_family_prompt.append((family, new_prompt))\n",
    "            \n",
    "        else:\n",
    "            if len(content_for_summarization[family][\"content\"][\"PROS\"]) > 0 or len(content_for_summarization[family][\"content\"][\"CONS\"]) > 0:\n",
    "                new_prompt = content_for_summarization[family]['prompt'].replace(\"PROS_AND_CONS\", str(content_for_summarization[family][\"content\"]))\n",
    "                per_family_prompt.append((family, new_prompt))\n",
    "\n",
    "    await tqdm_asyncio.gather(\n",
    "        *(executer(fam_and_prompt, content_for_summarization) for fam_and_prompt in per_family_prompt)\n",
    "    )\n",
    "\n",
    "    print(f\"Finished generating review summaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b19c12-c0b4-4651-8af4-a4a66060ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "await generate_summary_with_rate_limit(content_for_summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691bec52-6fd2-439c-9841-0ba3c5a4ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "await generate_summary_with_rate_limit(content_for_summarization_llm, use_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9156bb6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key, value in content_for_summarization.items():\n",
    "    print(f\"Product family: {key}\")\n",
    "    print(f\"Summary ReviewWeaver: {content_for_summarization_llm[key]['summary']}\\nSummary LLM: {value['summary']}\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b2044e-8c13-4d73-9d6f-c47a3966ca28",
   "metadata": {},
   "source": [
    "#### Uncomment the following section to save the files. But these files are already in the directory having summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee3bcbb3-912c-43db-926c-a2c6e62bfa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Save the defaultdict to a file\n",
    "# with open('../data/summaries-revieweaver.pkl', 'wb') as f:\n",
    "#     pickle.dump(content_for_summarization, f)\n",
    "\n",
    "# with open('../data/summaries-llm.pkl', 'wb') as f:\n",
    "#     pickle.dump(content_for_summarization_llm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7384692a-dc75-4ab1-842a-3f3f57379e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "mypipenv2",
   "name": "pytorch-gpu.2-0.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m109"
  },
  "kernelspec": {
   "display_name": "mypipenv2",
   "language": "python",
   "name": "mypipenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
